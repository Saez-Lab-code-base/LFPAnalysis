{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a1019c2",
   "metadata": {},
   "source": [
    "# Preprocessing raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d5796b",
   "metadata": {},
   "source": [
    "So you've recorded data in the Epilepsy monitoring unit - congratulations! What now? How do we load that data into a format that plays nice with Python, preprocess that data, and save it in a re-usable way? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c7071f",
   "metadata": {},
   "source": [
    "The LFPAnalysis codebase  contains a lot of functions to help with this. You can always dig into what those functions are doing (I encourage this) but in the notebooks I will simply show you how to **use** these functions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d885606",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5b9118",
   "metadata": {},
   "source": [
    "First, import Python packages and code you'll need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "903fdada",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import mne\n",
    "import pandas as pd\n",
    "import warnings \n",
    "\n",
    "# I only want to see warnings once\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cd439a",
   "metadata": {},
   "source": [
    "**ACTION**: If you have installed the LFPAnalysis you must append the local path!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10b3889b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/Users/salmanqasim/Documents/GitRepos/LFPAnalysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52ec53b",
   "metadata": {},
   "source": [
    "Import the custom functions from LFPAnalysis that we want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b549c60",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from LFPAnalysis import lfp_preprocess_utils, sync_utils, analysis_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ae1c39",
   "metadata": {},
   "source": [
    "## IF USING YOUR OWN DATA: Pre-process (run 1x): "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f0c76f",
   "metadata": {},
   "source": [
    "In the pre-processing functions below, we: \n",
    "\n",
    "1. load the raw data (either a .edf file or a folder of .nlx files) into mne objects for use with the mne toolbox: https://mne.tools/stable/index.html.\n",
    "\n",
    "2. load the localized electrode names from the .csv or .xlsx file listing their MNI coordinates into the mne object\n",
    "\n",
    "3. filter and resample as necessary\n",
    "\n",
    "4. re-reference "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1774ad4e-52ba-43b7-83f9-328af06eab32",
   "metadata": {},
   "source": [
    "**NOTE**: this notebook is meant to use the sample data, stored locally in the repo. This local data was pre-processed using the follow cell, which you will need to uncomment and modify according to your own data folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d83f681a",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for ix, subj_id in enumerate(subj_ids): \n",
    "#     site = subj_sites[ix] # where the data was recorded, e.g. 'MSSM', 'UI'\n",
    "#     format = subj_formats[ix] # the format the data, e.g. 'edf', 'nlx'\n",
    "    \n",
    "#     print(f'Working on subj {subj_id}')\n",
    "    \n",
    "#     # Set paths\n",
    "#     load_path = f'{base_dir}/projects/guLab/Salman/EMU/{subj_id}/neural/Day1'\n",
    "#     elec_path = f'{base_dir}/projects/guLab/Salman/EMU/{subj_id}/anat/'\n",
    "#     save_path = f'{base_dir}/projects/guLab/Salman/EphysAnalyses/{subj_id}/neural/Day1'\n",
    "    \n",
    "#     # Check if path exists for saving, and if not, make it\n",
    "#     if not os.path.exists(save_path):\n",
    "#         os.makedirs(save_path)\n",
    "\n",
    "#     # electrode files could either be csv or excel\n",
    "#     elec_files = glob(f'{elec_path}/*.csv') + glob(f'{elec_path}/*.xlsx')\n",
    "#     # There should really only be one, so grab it with the zero-index \n",
    "#     elec_file = elec_files[0]\n",
    "\n",
    "#     # Make MNE file\n",
    "#     mne_data = lfp_preprocess_utils.make_mne(load_path=load_path, \n",
    "#                                              elec_path=elec_file,\n",
    "#                                              format=format,\n",
    "#                                              return_data=True,\n",
    "#                                              site=site,\n",
    "#                                              check_bad=False) # changed this to not annotate anything as bad \n",
    "\n",
    "#     # Save this data so that you don't need this step again:\n",
    "#     mne_data.save(f'{save_path}/raw_ieeg.fif', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8202c122",
   "metadata": {},
   "source": [
    "If you are not using your own data (e.g. trying out the sample data) then you can just proceed from this point onwards. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9835543d",
   "metadata": {},
   "source": [
    "## Re-reference the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f462f2e-2a28-47c3-bce4-6e064ec4f1c0",
   "metadata": {},
   "source": [
    "We re-reference the data to get rid of shared noise, cleaning the data to leave what we assume is local biological activity. \n",
    "\n",
    "Read more in [this nice chapter from Parish et al.](https://link.springer.com/chapter/10.1007/978-3-031-20910-9_28)\n",
    "\n",
    "Here, note that we default to a bipolar configuration. This is my personal preference for my datasets but you have the freedom to use a white matter reference as well. I have not implemented a Laplacian or common-average referencing scheme yet. \n",
    "\n",
    "Note also that re-referencing requires modifying the electrode dataframes that contain the names and regions of each electrode. This is pretty easy in the bipolar montage but keep in mind if you implement a different method for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3958acf5",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Users/salmanqasim/Documents/GitRepos/LFPAnalysis/data/sample_ieeg.fif...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isotrak not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 394061 =      0.000 ...   788.122 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 394061  =      0.000 ...   788.122 secs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sEEG channel type selected for re-referencing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating RawArray with float64 data, n_channels=15, n_times=394062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 394061 =      0.000 ...   788.122 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added the following bipolar channels:\n",
      "racas1-racas2, racas2-racas3, racas3-racas4, racas4-racas5, racas5-racas6, racas6-racas7, racas8-racas9, racas9-racas10, rmolf1-rmolf2, rmolf2-rmolf3, rmolf3-rmolf4, rmolf4-rmolf5, rmolf5-rmolf6, rmolf9-rmolf10, rmolf10-rmolf11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /Users/salmanqasim/Documents/GitRepos/LFPAnalysis/data/sample_ieeg_bp.fif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing /Users/salmanqasim/Documents/GitRepos/LFPAnalysis/data/sample_ieeg_bp.fif\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[done]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n",
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n",
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n",
      "/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/LFPAnalysis/../data/YBA_ROI_labelled.xlsx\n"
     ]
    }
   ],
   "source": [
    "site = 'MSSM' # where the data was recorded, e.g. 'MSSM', 'UI'\n",
    "format = 'edf' # the format the data, e.g. 'edf', 'nlx'\n",
    "    \n",
    "# Set load path\n",
    "load_path = '/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/data'\n",
    "\n",
    "# Load electrode file \n",
    "elec_file = f'{load_path}/sample_labels.xlsx'\n",
    "\n",
    "# Make MNE file\n",
    "mne_data = mne.io.read_raw_fif(f'{load_path}/sample_ieeg.fif', preload=True)\n",
    "\n",
    "\n",
    "# Re-reference neural data\n",
    "mne_data_reref = lfp_preprocess_utils.ref_mne(mne_data=mne_data, \n",
    "                                              elec_path=elec_file, \n",
    "                                              method='bipolar', \n",
    "                                              site=site)\n",
    "\n",
    "# Save this data so that you don't need this step again:\n",
    "mne_data_reref.save(f'{load_path}/sample_ieeg_bp.fif', overwrite=True)\n",
    "\n",
    "# Should also save out re-referenced elec_file: \n",
    "\n",
    "elec_data = lfp_preprocess_utils.load_elec(elec_file)\n",
    "anode_list = [x.split('-')[0] for x in mne_data_reref.ch_names]\n",
    "elec_df = elec_data[elec_data.label.str.lower().isin(anode_list)]\n",
    "elec_df['label'] =  elec_df.label.apply(lambda x: [a for a in mne_data_reref.ch_names if str(x).lower() in a.split('-')[0]][0])\n",
    "\n",
    "# Add region to the data frame \n",
    "\n",
    "manual_col = [col for col in elec_df.columns if 'manual' in col.lower()][0]\n",
    "all_regions = [] \n",
    "for chan_name in elec_df.label.unique():\n",
    "    elec_region = analysis_utils.select_rois_picks(elec_df, chan_name, manual_col=manual_col)\n",
    "    all_regions.append(elec_region) \n",
    "\n",
    "elec_df['salman_region'] = all_regions\n",
    "elec_df['hemisphere'] = elec_df.label.apply(lambda x: x[0])\n",
    "\n",
    "elec_df.to_csv(f'{load_path}/sample_labels_bp', index=False)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff05564",
   "metadata": {},
   "source": [
    " - mne_data: a Raw mne object, where the data has been loaded, filtered for line noise, parsed for different data types, and resampled if necessary. \n",
    " \n",
    " - mne_data_reref: an mne object containing re-referenced data (either white matter or bipolar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1b53a3d",
   "metadata": {},
   "source": [
    "## NOW look at the data to manually remove channels: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b12839",
   "metadata": {},
   "source": [
    "After bipolar referencing: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eeca6f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e892ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scroll up/down and left/right using your keyboard. CLICK on a channel to turn it 'grey' and mark as a 'bad' channel. \n",
    "# # If you click a grey channel again it will unmark it. \n",
    "\n",
    "# mne_data_reref = mne.io.read_raw_fif(f'{load_path}/sample_ieeg_bp.fif', preload=True)\n",
    "# fig = mne_data_reref.plot(start=0, duration=120, n_channels=30, \n",
    "#                       scalings=mne_data_reref._data.max()/30\n",
    "#                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90817f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ALSO look at the power spectra! \n",
    "# # You can click on channels here to identify them, and go back to the viz above to mark them as noise if need be\n",
    "\n",
    "# mne_data_reref.compute_psd().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d310de9",
   "metadata": {},
   "source": [
    "If you have ran the preprocessing above, load the data instead: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b657ca72",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Users/salmanqasim/Documents/GitRepos/LFPAnalysis/data/sample_ieeg_bp.fif...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 394061 =      0.000 ...   788.122 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 394061  =      0.000 ...   788.122 secs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Users/salmanqasim/Documents/GitRepos/LFPAnalysis/data/sample_photodiode.fif...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Isotrak not found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 807039 =      0.000 ...   788.124 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 807039  =      0.000 ...   788.124 secs...\n"
     ]
    }
   ],
   "source": [
    "load_path = '/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/data'\n",
    "\n",
    "elec_file = f'{load_path}/sample_labels.xlsx'\n",
    "\n",
    "elec_data = lfp_preprocess_utils.load_elec(elec_file)\n",
    "\n",
    "mne_data_reref = mne.io.read_raw_fif(f'{load_path}/sample_ieeg_bp.fif', preload=True)\n",
    "\n",
    "photodiode_data = mne.io.read_raw_fif(f'{load_path}/sample_photodiode.fif', preload=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e10c5",
   "metadata": {},
   "source": [
    " - mne_dict: a dictionary containing all of your subjects' re-referenced mne data \n",
    " \n",
    " - photodiode_dict: a dictionary containing all of your subjects' photodiode data \n",
    " \n",
    " - elec_dict: a dictionary containing the paths to your subjects' electrode data "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9b7377",
   "metadata": {},
   "source": [
    "## Sync behavioral and neural data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b57df8f",
   "metadata": {},
   "source": [
    "Here, we perform a critical step: computing the time offset between the computer that recorded the neural data and the laptop that featured the experiment. \n",
    "\n",
    "The function here only requires a **subset** of detected sync signals (i.e. photodiode deflections) to be detected to successfully compute this offset. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a501a02c-8417-4608-b8ab-dcefe44c53f8",
   "metadata": {},
   "source": [
    "First, you may need to MANUALLY clean the photodiode signal if the recording quality is poor. Load it, plot it, and try to isolate/amplify the pulses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "480fb71d",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 blocks\n",
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "\n",
      "found matches for 150 of 428 pulses\n",
      "0.9999892560991055\n",
      "-228.2080128605071\n"
     ]
    }
   ],
   "source": [
    "time_df = pd.read_csv(f'{load_path}/sample_ts.csv')\n",
    "# Load in the timestamps pertaining to your sync. If your task had a square pop up, for example, grab the times for that square's appearance from the behavioral logs.\n",
    "# Below, I do this for my own task's Psychopy output, but yours is probably coded differently. \n",
    "\n",
    "# Synchronize to the photodiode or whatever your neural sync signal is\n",
    "height = 1\n",
    "windSize = 15\n",
    "smoothSize = 11\n",
    "\n",
    "slope, offset = sync_utils.synchronize_data(time_df['beh_ts'].values, \n",
    "                                            photodiode_data, \n",
    "                                            smoothSize=smoothSize, windSize=windSize, height=height)\n",
    "\n",
    "print(slope)\n",
    "print(offset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fcdc1d",
   "metadata": {},
   "source": [
    " - slopes: a dictionary containing the slopes (should be ~ 1) for each subject\n",
    " - offsets: a dictionary containing the offsets for each subject"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd052688",
   "metadata": {},
   "source": [
    "## Load your behavioral data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed1451c",
   "metadata": {},
   "source": [
    "You probably have a separate notebook for processing the behavioral data for your task. Load the processed dataframe here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f4de3ab8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "behav_data = pd.read_csv(f'{load_path}/sample_beh.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f9e1bc09",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trials</th>\n",
       "      <th>feedback_start</th>\n",
       "      <th>baseline_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>243.239158</td>\n",
       "      <td>244.929025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>248.344187</td>\n",
       "      <td>250.043187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>254.083059</td>\n",
       "      <td>255.790670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>258.148220</td>\n",
       "      <td>259.838892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>261.943712</td>\n",
       "      <td>263.620631</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   trials  feedback_start  baseline_start\n",
       "0       1      243.239158      244.929025\n",
       "1       2      248.344187      250.043187\n",
       "2       3      254.083059      255.790670\n",
       "3       4      258.148220      259.838892\n",
       "4       5      261.943712      263.620631"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "behav_data.head(5)[['trials', 'feedback_start', 'baseline_start']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2833f764",
   "metadata": {},
   "source": [
    "## Make epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2944dc32",
   "metadata": {},
   "source": [
    "Make epochs and remove IEDs. Currently just doing this for one example period - when subjects receive feedback. \n",
    "\n",
    "Notes: \n",
    "\n",
    "- I also segment a baseline period for every event of interest. \n",
    "\n",
    "- I apply a buffer period of 1.0 seconds - this will be helpful when we compute spectrograms later. \n",
    "\n",
    "- The IED count for every channel is added to the epoch metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65b21a",
   "metadata": {},
   "source": [
    "(I'm a little dumb, so my baseline is a fixation cross AFTER the trial, rather than before. A bit silly if you ask me.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63a53422",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Users/salmanqasim/Documents/GitRepos/LFPAnalysis/data/sample_ieeg_bp.fif...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 394061 =      0.000 ...   788.122 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 394061  =      0.000 ...   788.122 secs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 25 - 80 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIR filter parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Windowed time-domain design (firwin) method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Lower passband edge: 25.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Lower transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 21.88 Hz)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Upper passband edge: 80.00 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Filter length: 265 samples (0.530 s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:    0.8s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['feedback_start']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 matching events found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 80 events and 2001 original time points ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /Users/salmanqasim/Documents/GitRepos/LFPAnalysis/data/sample_ieeg_bp.fif...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Range : 0 ... 394061 =      0.000 ...   788.122 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ready.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading 0 ... 394061  =      0.000 ...   788.122 secs...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up band-pass filter from 25 - 80 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FIR filter parameters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Windowed time-domain design (firwin) method\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Lower passband edge: 25.00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Lower transition bandwidth: 6.25 Hz (-6 dB cutoff frequency: 21.88 Hz)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Upper passband edge: 80.00 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Upper transition bandwidth: 20.00 Hz (-6 dB cutoff frequency: 90.00 Hz)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Filter length: 265 samples (0.530 s)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:    0.1s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 10 concurrent workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  15 | elapsed:    0.2s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Used Annotations descriptions: ['baseline_start']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not setting metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 matching events found\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No baseline correction applied\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 projection items activated\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using data from preloaded Raw for 80 events and 1376 original time points ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 bad epochs dropped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting existing file.\n"
     ]
    }
   ],
   "source": [
    "# set some windows of interest \n",
    "\n",
    "buf = 1.0 # this is the buffer before and after that we use to limit edge effects for TFRs\n",
    "\n",
    "IED_args = {'peak_thresh':5,\n",
    "           'closeness_thresh':0.25, \n",
    "           'width_thresh':0.2}\n",
    "\n",
    "evs = {'feedback_start': [-0.5, 1.5],\n",
    "       'baseline_start': [0, 0.75]}\n",
    "\n",
    "load_path = '/Users/salmanqasim/Documents/GitRepos/LFPAnalysis/data'\n",
    "\n",
    "epochs_all_evs = {f'{x}': np.nan for x in evs}\n",
    "for event in evs.keys():\n",
    "    pre = evs[event][0]\n",
    "    post = evs[event][1]\n",
    "    fixed_baseline = None\n",
    "    behav_times = behav_data[event]\n",
    "\n",
    "    # THE following function will now SAVE out dataframes that indicate IED and artifact time points in your data\n",
    "    epochs = lfp_preprocess_utils.make_epochs(load_path=f'{load_path}/sample_ieeg_bp.fif', \n",
    "                                              slope=slope, offset=offset, \n",
    "                                              behav_name=event, behav_times=behav_times,\n",
    "                                              ev_start_s=pre, ev_end_s=post, buf_s=1, downsamp_factor=None, IED_args=IED_args, detrend=0)\n",
    "\n",
    "\n",
    "    epochs_all_evs[event] = epochs\n",
    "    epochs_all_evs[event].save(f'{load_path}/sample_{event}-epo.fif', overwrite=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0abb83a",
   "metadata": {},
   "source": [
    " - epochs_all_evs: dictionary containing the epochs for all of your subjects' re-referenced data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7661bf",
   "metadata": {},
   "source": [
    "Plot and examine the epochs if you'd like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af96abae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook\n",
    "# fig = epochs_all_subjs_all_evs['MS007']['feedback_start'].plot(n_epochs=10, n_channels=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6261e54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Need this following line to save the annotations to the epochs object \n",
    "# fig.fake_keypress('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80af3e03",
   "metadata": {},
   "source": [
    "## Where do I go from here? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5654949-ac77-4f95-b8bd-20451b63b8c6",
   "metadata": {},
   "source": [
    "At this point, you've successfuly pre-processed your iEEG data and sliced it around your timepoints of interest. These epochs are going to be the currency for many of your subsequent analyses, so make sure you TRUST THEM before proceeding to the other notebooks for analyses. \n",
    "\n",
    "From here, you can move on to the:\n",
    "\n",
    "1. FOOOF: a notebook for computing power-spectra across trials and fitting their peaks \n",
    "\n",
    "2. TFRPlotsAndStatistics: a notebook for computing time-frequency spectra (trial-level), and computing several different statistics or simply saving the data out in dataframes. \n",
    "\n",
    "3. OscillationDetection(BOSC): a notebook for computing sliding burst detection and saving the data out in dataframes \n",
    "\n",
    "4. TimeResolvedRegression: a notebook for computing regression analysis at each timepoint of a timeseries. TFR-extracted band power is used as example. \n",
    "\n",
    "5. ConnectivityAnalysis: a notebook for computing different synchrony measures between electrodes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2ba37e",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lfpanalysis",
   "language": "python",
   "name": "lfpanalysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}